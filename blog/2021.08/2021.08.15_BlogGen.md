!!title Blog Generation
!!summary New project: Starting a blog generator/compiler.
!!keywords rust verlet integrator 2d rain world deterministic starting over 3d pixel art blog generation markdown
!!series blog_gen chaostar

## 0628

I do wonder whether the Verlet integrator is the right approach. I suppose that's true for every single venture. 

To be honest, while the idea of procedural animation is fantastic, I am not sold that I can do it in a reasonable time. I love the idea of a Rust based engine, but am not sure I can hack it quickly. 

I think today I'll play around with other projects, such as fleshing out the markdown to html generator. If I do come back to Chaostar later today, I'll work on a different piece instead of the integrator.

For now I'm starting up a new `md_to_html` Rust project. 

## 0745

I've fleshed out the basic structure for `md_to_html`. I've been trying to develop most of my utility tools as CLI programs so that way I can wire them up into shell scripts. It should also enable CI/CD usage.

Here's the main:

```
// main.rs

fn main() {
    let env_args: Vec<String> = env::args().collect();

    check_for_flags(&env_args);

    let input_folder = match get_input_folder(&env_args) {
        Ok(input) => input,
        Err(e) => {
            print_err(e);
            print_well_formed_example();
            return;
        }
    };

    let output_folder = match get_output_folder(&env_args) {
        Ok(output) => output,
        Err(e) => {
            print_err(e);
            print_well_formed_example();
            return;
        }
    };

    let files = crawler::crawl(input_folder).unwrap();
    let parsed_files = parser::parse(files).unwrap();
    let checked_files = checker::check(parsed_files).unwrap();
    let generated = generator::generate(checked_files);

    // Go through and execute each op.
    for op in generated {
        match op {
            // Things like 'write this binary to this file'
            // or 'wipe output directory'
            // etc.
        }
    }
}
```

It follows a simple compiler pattern, where 
1) The input folder + output folder are collected.
2) The files are crawled + sourced by the `crawler::crawl()`.
3) Files are then parsed into an intermediate representation in `parser::parse()`. These ensure that they follow the proper rules I'll be building out, such as code ticks must be closed. Errors are batched and progress halts.
4) Files are then checked in `checker::check()`. Things like links, resources, etc. are validated. Errors are batched and progress halts.
5) The checked files are finally ran through a generator which creates a list of ops that should be executed. Things like 'write this binary to this path', etc. I've found that writing a simple interpreter for these things has value and enables one to cleanly separate file i/o from commands.

This version will be done as a single threaded one, but could easily go wide if need be. I tend to take the approach of get a simple version working, boost performance as time goes on.


## 0824

The `crawler` mod is fairly simple. It goes through an input folder and sources all files. It doesn't load anything, just compares the files found against a whitelist for things I can handle. 

As I add things over time, I'll know when I need to update the code as it will throw errors when a new file type is encountered.

```
//crawler/mod.rs

/// Crawls the input folder, returning a list of files.
pub fn crawl(input_folder: InputFolder) -> Result<Files, Error> {
    let dir = input_folder.to_string();

    let mut files = Files {
        md_paths: vec![],
        gif_paths: vec![],
    };

    let mut errors = vec![];

    for entry in WalkDir::new(&dir)
        .into_iter()
        .filter_map(Result::ok)
        .filter(|e| !e.file_type().is_dir())
    {
        let path = entry.path();
        let path_string = String::from(path.to_str().unwrap_or("".into()));

        if let Some(extension) = path.extension() {
            if let Some(extension) = extension.to_str() {
                match extension.to_lowercase().as_str() {
                    "gif" => {
                        files.gif_paths.push(path_string);
                    }
                    "md" => {
                        files.md_paths.push(path_string);
                    }
                    _ => errors.push(Error::UnhandledFileType {
                        path: path_string,
                        file_type: String::from(extension),
                    }),
                }
            }
        }
    }

    if errors.len() != 0 {
        panic!("{:#?}", errors)
    }

    Ok(files)
}
```


## 0940

Parser is going along nicely. I've got the HTML titles, dates, next/previous blog entries and file paths parsed. 

The next step will be converting it to elements that will then be ran through the checker. From there, it'll be ran through the generator and I'll be finished.

## 1025

The formatting is garbage, but it is coming together. I expect this to grow over time, but for now I simply want to have a basic HTML page that's spit out that I can then tweak. 

I have yet to do an `index.html`, but I'm not sure I even want my blog posts to have that. This branch will get merged in when I have a more or less complete generator/compiler. 

I don't want to have to deal with updating this all the time, so I'll get it to a spot where I do not need to touch it again any time soon. 

## 1307

It's sort of funny how designs can become something horrid. My parser, while functional, has a ton of issues with actually parsing things. It confuses lists or `vecs` with markdown links. I'm going to try a different approach, a recursive one that iterates over and over on some input until it can't reduce it any more. This may get horridly complex and expensive, but I'm shooting for simplicity right now.

My approach will be as follows:
1) Take in a `Vec<Thing>`. If it's a `Unprocessed` element, it will attempt to break it down into something else. If it cannot, then processing ends and it will be returned as raw text.
2) The first element I will try to break down will be code blocks. This is substantially different than most things, and so it should be easier to start with.
3) The next element I will attempt to break down will be a link. 

## 1507

Honestly this has moved along better than I thought. There's still some bugginess around link generation, but it's acceptable enough to move on. 

Rather than build a 100% full functioned generator that can handle anything, this will specifically be used for blogging. 

It will have some data driven components, such as a `styles.css` file and perhaps some JS that is generated, but overall it's used for generating static pages.

## 1603

I do like taking taking a break from the normal work. The next thing I'll end up doing is writing up a CI/CD (or some form of deployment pipeline) to put this online. 

I'll get this to a point where I can reliably spit out HTML pages, then I'll merge this in after cleaning up the code. From there I'll go back to Chaostar and in about two weeks I'll switch to the deployment stage of things. 

## 1739

I'm becoming more enthralled with cross platform development. While the perfect world would be something like Haxe, except I write it, I don't think I can do that. 

It's too big of an undertaking for me right now, though I suspect some echoes of it will happen as time goes on. 

One thing I would be interested in is a sub language that has the properties of Lisp, but is essentially a lighter weight Rust. 

Rust can be verbose, and take you down rabbit holes. Whereas in say JavaScript you have different concerns, after the footguns of course, where you are more concerned about the structure of the code. 

Rust can lead you down the path of genericness, which while appealing, rarely has real world impacts. 

I speak purely from experience where the more I make code generic, writing traits or otherwise 'future proofing', the less value it has and the higher rate of project failure. This makes one understand Go a bit more.  

Another realization I have had is that whether it is web, Android, iOS, a console, VR or a game engine, I can't make it bullet proof and future proof. 

With 3rd party vendors increasingly shifting the ecosystem, I can't rely on one thing being perfect forever. 

Security may change, permissions may change, etc. It would be better to shift all computation and such to a server I control. While certain ones, such as Outriders, may feel terrible this seems like the way forward. Something like the [Tribes 2 model](https://www.gamedevs.org/uploads/tribes-networking-model.pdf) would be ideal. 

The core code of the client could likely remain the same, being FFI'd into each separate client. The client specific code itself would remain native, either in Objective C, JS, Java, Kotlin, C++, whichever. 

An attribute system based on tags could be utilized on Rust code, and then a generator is ran on all source code to create up to date libraries for each client. 

I would likely have a facade with an interface the client could call, with the Rust core spun up in a separate background thread. 


## 2130

I have code sections, single code variables, gifs and links being converted. 