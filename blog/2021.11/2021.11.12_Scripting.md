!!title Adding in a scripting environment
!!summary Adding in a basic scripting environment.
!!keywords rust open source mit timer timing crate library gamedev ggez job queue multithreading scripting
!!series gamedev

## 0836

I'll be adding in a very basic scripting environment today. First I'll showcase the script parsing.

There's a few rules:
* Tokens are split on whitespace
* Comments start with `;` and end on newlines
* Comments terminate any previous token

I could easily make this more complicated, but I want a scripting language that is easy to implement, somewhat powerful and allows easy modding.

It will likely be stack based in some way, but I don't want it to be too complicated. A eventual goal is to make a bytecode compiler, but for now it's going to parse the script into memory, store the ops, then allow it to be used.

Why add in a scripting language? Simple: I want to hot reload the program without mucking with the core engine.

The basic approach will be to load a program, doing parsing + validation, then saving the ops and starting execution. 

I will likely have one instance of each scripting environment per entity for simplicity. Another key feature will be the ability to 'suspend' entity execution. This can allow many interesting effects, such as real time pause, pause menus, or ensuring that an entire simulation slowly progresses without blocking the main thread if it gets too crazy.

Without further ado, I'll go over my `Script` class. This simply parses out tokens, adding in line numbers, columns and the token itself.

First I'll define the token and script structs:

```
/// A single token in the script
#[derive(Clone, Debug, PartialEq)]
pub struct Token {
    pub column: usize,
    pub is_comment: bool,
    pub line: usize,
    pub token: String,
}


/// Representation of a script.
pub struct Script {
    tokens: Vec<Token>,
}
```

The real guts of this is the creation of the script. No validation or anything of the sort will be done in here, just the parsing of tokens and their positions.

```
impl Script {
    /// Creates a new script
    pub fn new<'a>(script: &'a str) -> Self {
        // Simplify whitespace
        let script = str::replace(&script, "\r", "");

        let mut line = 0;
        let mut column = 0;
        let mut working_token: Option<Token> = None;
        let mut is_comment = false;

        let mut tokens = vec![];

        for c in script.chars() {
            let is_newline = c == '\n';
            let mut terminated = false;

            // Check if a comment should be started
            if c == ';' {
                is_comment = true;

                // Finish the last token
                if let Some(token) = working_token.take() {
                    tokens.push(token);
                }
            }

            // If making a comment, stop it on a new line.
            if is_comment && is_newline {
                is_comment = false;

                if let Some(token) = working_token.take() {
                    tokens.push(token);
                    terminated = true;
                }
            }

            if !terminated {
                // Attempt to create this token if it's on whitespace
                if c.is_whitespace() && !is_comment {
                    if let Some(token) = working_token {
                        tokens.push(token);
                    }

                    working_token = None;
                } else {
                    if let Some(token) = &mut working_token {
                        token.token.push(c);
                    } else {
                        working_token = Some(Token {
                            line,
                            column,
                            token: c.to_string(),
                            is_comment,
                        });
                    }
                }
            }

            // Increment line counts
            if is_newline {
                line += 1;
                column = 0;
            } else {
                column += 1;
            }
        }

        // Pop off last token
        if let Some(token) = working_token {
            tokens.push(token);
        }

        Self { tokens }
    }

    /// Returns the tokens in the script
    pub fn tokens(&self) -> &[Token] {
        &self.tokens
    }
}
```

I can do a ton with this simple parser, such as creating a Lisp, a Forth style program or a Python type language. My initial gut is a Forth style will be the way forward as stacks are fun and I want a concatenative language.

Last but not least are the tests. These were beneficial in catching edge cases.

```

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn only_whitespace_returns_empty_tokens() {
        let program = "\r\n\r\t   \t\n";
        let script = Script::new(program);

        let expected: Vec<Token> = vec![];
        assert_eq!(expected, script.tokens);
    }

    #[test]
    fn token_at_end_is_popped() {
        let program = "     Garbage";
        let script = Script::new(program);

        let expected: Vec<Token> = vec![Token {
            token: "Garbage".into(),
            line: 0,
            column: 5,
            is_comment: false,
        }];
        assert_eq!(expected, script.tokens);
    }

    #[test]
    fn tokens_split_on_whitespace() {
        let program = "  Garbage Day Bruh";
        let script = Script::new(program);

        let expected: Vec<Token> = vec![
            Token {
                token: "Garbage".into(),
                line: 0,
                column: 2,
                is_comment: false,
            },
            Token {
                token: "Day".into(),
                line: 0,
                column: 10,
                is_comment: false,
            },
            Token {
                token: "Bruh".into(),
                line: 0,
                column: 14,
                is_comment: false,
            },
        ];
        assert_eq!(expected, script.tokens);
    }

    #[test]
    fn tokens_split_on_newlines() {
        let program = "  Garbage \r\n Day Bruh \n TESTING! \t WUT";
        let script = Script::new(program);

        let expected: Vec<Token> = vec![
            Token {
                token: "Garbage".into(),
                line: 0,
                column: 2,
                is_comment: false,
            },
            Token {
                token: "Day".into(),
                line: 1,
                column: 1,
                is_comment: false,
            },
            Token {
                token: "Bruh".into(),
                line: 1,
                column: 5,
                is_comment: false,
            },
            Token {
                token: "TESTING!".into(),
                line: 2,
                column: 1,
                is_comment: false,
            },
            Token {
                token: "WUT".into(),
                line: 2,
                column: 12,
                is_comment: false,
            },
        ];
        assert_eq!(expected, script.tokens);
    }

    #[test]
    fn makes_single_comment_without_nl() {
        let program = "; a simple comment";
        let script = Script::new(program);

        let expected: Vec<Token> = vec![Token {
            token: "; a simple comment".into(),
            line: 0,
            column: 0,
            is_comment: true,
        }];
        assert_eq!(expected, script.tokens);
    }

    #[test]
    fn comment_terminates_token() {
        let program = "test; comment";
        let script = Script::new(program);

        let expected: Vec<Token> = vec![
            Token {
                column: 0,
                is_comment: false,
                line: 0,
                token: "test".into(),
            },
            Token {
                column: 4,
                is_comment: true,
                line: 0,
                token: "; comment".into(),
            },
        ];
        assert_eq!(expected, script.tokens);
    }

    #[test]
    fn makes_single_comment_terminated_by_nl() {
        let program = " a test ; a simple comment \nwut";
        let script = Script::new(program);

        let expected: Vec<Token> = vec![
            Token {
                column: 1,
                is_comment: false,
                line: 0,
                token: "a".into(),
            },
            Token {
                column: 3,
                is_comment: false,
                line: 0,
                token: "test".into(),
            },
            Token {
                column: 8,
                is_comment: true,
                line: 0,
                token: "; a simple comment ".into(),
            },
            Token {
                column: 0,
                is_comment: false,
                line: 1,
                token: "wut".into(),
            },
        ];
        assert_eq!(expected, script.tokens);
    }
}
```

Next session I'll go over the other types and possibly into the actual scripting environment.