!!title Summaries, Keywords and Validations
!!summary Building out validations, summaries, paragraphs and titles for pages.
!!keywords Rust validation summary metadata keywords seo paragraphs
!!series blog_gen

## 0819

I'll be implementing some SEO validations on the `Metadata` fields today. Also will be taking the time to retroactively apply these changes to all pages.

## 0911

All pages have been updated to pass the validation. Took some time adding in titles, summaries and keywords but it's now done. Fixed a few bugs I ran into as well, but they won't be covered here.

The main thing is checking the IR before returning from the md parser.

```
// parser/md/mod.rs

...

fn get_display_title(contents: &Item<ContentIr>) -> Res<String> {
    match &contents.item {
        ContentIr::Div {
            contents: content_ir,
        } => {
            for ir in content_ir.iter() {
                let item = Item {
                    location: contents.location.clone(),
                    item: ir.clone(),
                };

                let result = get_display_title(&item);
                match result {
                    Res::Error { .. } => {
                        // skip over to parse the next
                    }
                    _ => return result,
                }
            }
        }
        ContentIr::Metadata(m) => match m {
            Metadata::DisplayTitle(title) => {
                const MAX_SEO_TITLE_LEN: usize = 65;

                // Warn if there is no title
                if title.len() == 0 {
                    return Res::Warn {
                        item: Item {
                            item: "Placeholder!".into(),
                            location: contents.location.clone(),
                        },
                        msg: "Display title empty!".into(),
                    };
                }
                // Warn if over 65chars for SEO
                else if title.chars().count() >= MAX_SEO_TITLE_LEN {
                    return Res::Warn {
                        item: Item {
                            item: title.into(),
                            location: contents.location.clone(),
                        },
                        msg: format!(
                            "Display title exceeds {} characters! Got {}.",
                            MAX_SEO_TITLE_LEN,
                            title.chars().count()
                        ),
                    };
                }

                return Res::Ok(Item {
                    location: contents.location.clone(),
                    item: title.clone(),
                });
            }
            _ => {}
        },
        _ => {}
    }

    Res::Error {
        location: contents.location.clone(),
        msg:
            "Display title not found! Start each page with '!!title YOUR TITLE' ended with newline."
                .into(),
    }
}

fn get_keywords(contents: &Item<ContentIr>) -> Res<Vec<String>> {
    const MIN_KEYWORDS_LEN: usize = 5;

    match &contents.item {
        ContentIr::Div {
            contents: content_ir,
        } => {
            for ir in content_ir.iter() {
                let item = Item {
                    location: contents.location.clone(),
                    item: ir.clone(),
                };

                let result = get_keywords(&item);
                match result {
                    Res::Error { .. } => {
                        // skip over to parse the next
                    }
                    _ => return result,
                }
            }
        }
        ContentIr::Metadata(m) => match m {
            Metadata::Keywords(words) => {
                if words.len() == 0 {
                    return Res::Warn {
                        item: Item {
                            item: vec!["A".into(), "Placeholder!".into()],
                            location: contents.location.clone(),
                        },
                        msg: "Keywords empty!".into(),
                    };
                }
                // SEO optimization
                else if words.len() < MIN_KEYWORDS_LEN {
                    return Res::Warn {
                        item: Item {
                            item: words.clone(),
                            location: contents.location.clone(),
                        },
                        msg: format!(
                            "Keywords should have at least {} words! Got {}.",
                            MIN_KEYWORDS_LEN,
                            words.len()
                        ),
                    };
                }

                return Res::Ok(Item {
                    location: contents.location.clone(),
                    item: words.clone(),
                });
            }
            _ => {}
        },
        _ => {}
    }

    Res::Error {
        location: contents.location.clone(),
        msg:
            "Keywords not found! Start each page with '!!keywords A LIST OF KEYWORDS' ended with newline."
                .into(),
    }
}

fn get_summary(contents: &Item<ContentIr>) -> Res<String> {
    const MIN_META_DESCRIPTION_LEN: usize = 30;
    const MAX_META_DESCRIPTION_LEN: usize = 160;

    match &contents.item {
        ContentIr::Div {
            contents: content_ir,
        } => {
            for ir in content_ir.iter() {
                let item = Item {
                    location: contents.location.clone(),
                    item: ir.clone(),
                };

                let result = get_summary(&item);
                match result {
                    Res::Error { .. } => {
                        // skip over to parse the next
                    }
                    _ => return result,
                }
            }
        }
        ContentIr::Metadata(m) => match m {
            Metadata::Summary(summary) => {
                if summary.len() == 0 {
                    return Res::Warn {
                        item: Item {
                            item: "A placeholder!".into(),
                            location: contents.location.clone(),
                        },
                        msg: "Summary empty!".into(),
                    };
                } else if summary.chars().count() < MIN_META_DESCRIPTION_LEN {
                    return Res::Warn {
                        item: Item {
                            item: summary.clone(),
                            location: contents.location.clone(),
                        },
                        msg: format!(
                            "Summary should have a minimum len of {}! Got {}.",
                            MIN_META_DESCRIPTION_LEN,
                            summary.chars().count()
                        ),
                    };
                } else if summary.chars().count() > MAX_META_DESCRIPTION_LEN {
                    return Res::Warn {
                        item: Item {
                            item: summary.clone(),
                            location: contents.location.clone(),
                        },
                        msg: format!(
                            "Summary should have a maximum len of {}! Got {}.",
                            MAX_META_DESCRIPTION_LEN,
                            summary.chars().count()
                        ),
                    };
                }

                return Res::Ok(Item {
                    location: contents.location.clone(),
                    item: summary.clone(),
                });
            }
            _ => {}
        },
        _ => {}
    }

    Res::Error {
        location: contents.location.clone(),
        msg:
            "Keywords not found! Start each page with '!!keywords A LIST OF KEYWORDS' ended with newline."
                .into(),
    }
}
```


For other types of validations that can be done in parallel, I'll follow the same pattern as above. Another thing I would like to do is paragraph warnings/validations as well to ensure consistent formatting and flow.  

Here's the current remaining tasks:
* Paragraph validation
* Index page generation
* Link validations
* Navigation
* Series
* Misc tweaks such as lowercasing file names, folders, etc.
* Config.json files

I think I should be able to knock most of that out in the next week or so.


## 1413

Next up is paragraph parsing + length enforcement. I'm making the validations here all warnings.

A new `Paragraph` element is added.

```
// html/element.rs

...

impl Html for Element {
    fn to_html(&self) -> String {
        let class = {
            if self.classes.is_empty() {
                String::default()
            } else {
                format!(
                    "class=\"{}\"",
                    self.classes
                        .iter()
                        .map(|c| c.selector().to_str().into())
                        .collect::<Vec<String>>()
                        .join(" ")
                )
            }
        };

        let selector;
        let mut children = String::new();
        let mut attributes: Option<String> = None;

        match &self.kind {
            
            ...

            Kind::Paragraph { children: c } => {
                selector = String::from("p");
                children = c.iter().map(|e| e.to_html()).collect();
            }
           
            ...

        }

        let attributes = match attributes {
            Some(s) => s,
            None => String::default(),
        };

        let id = match &self.id {
            Some(id) => format!("id=\"{}\"", id),
            None => String::default(),
        };

        format!(
            "<{} {} {} {}>{}</{}>",
            selector, id, attributes, class, children, selector
        )
    }
}

...

#[derive(Clone, Debug, PartialEq)]
pub enum Kind {
    ...

    Paragraph {
        children: Vec<Element>,
    },

    ...
}

...


pub fn p(children: Vec<Element>) -> Element {
    Element {
        classes: vec![],
        id: None,
        kind: Kind::Paragraph { children },
    }
}

...

```

I'll add some new parsing `Options` to skip paragraphs if needed. This will be applied to the `list` `chomp`er to prevent strange things from happening.

```
// parser/md/parse_contents/chomp/list.rs

pub fn list(
    contents: &String,
    mut opts: Options,
    validations: &Validations,
) -> Option<Vec<ContentIr>> {
    let opts = {
        opts.make_cards = false;
        opts.make_paragraphs = false;
        opts
    };

    ...
}

```

A new `Paragraph` `ContentIr` is added.

```
// parser/md/parse_contents/content_ir.rs

...

#[derive(Clone, Debug, PartialEq)]
pub enum ContentIr {
    
    ...
    
    Paragraph {
        children: Vec<ContentIr>,
    },
   
    ...

}

...

```

The `parse_contents` module is updated to account for various hierarchical mappings. Those are split into a separate module.

A bug with warnings not being returned was fixed as well.

```
// parser/md/parse_contents/mod.rs

...


pub fn execute(contents: String, location: Location, opts: Options) -> Res<ContentIr> {
    let mut warnings = vec![];

    // Preprocess things to simplify parsing.
    let contents = {
        let mut contents = contents.replace("\r\n", "\n");

        // Add a newline to ensure that it gets processed correctly
        if !contents.ends_with("\n") {
            contents.push('\n');
        }

        contents
    };

    // Since this is a recursive processor, executing until nothing remains, set it up so that nothing has
    // been processed yet.
    let mut ir = vec![ContentIr::Unparsed {
        contents,
        validations: Validations {
            skip_code_block: false,
            skip_header: false,
            skip_inline_code: false,
            skip_link: false,
            skip_list: false,
            skip_metadata_display_title: false,
            skip_metadata_keywords: false,
            skip_metadata_summary: false,
        },
    }];

    // Continue processing + reprocessing all elements until there's nothing left.
    loop {
        let result = match parse(&ir, &location, opts) {
            Res::Ok(item) => item.item,
            Res::Warn { item, msg } => {
                warnings.push((msg, item.location.clone()));
                item.item
            }
            Res::Error { location, msg } => return Res::Error { location, msg },
            Res::Warnings { item, mut msgs } => {
                warnings.append(&mut msgs);
                item.item
            }
        };

        let (new_elements, continue_running) = result;

        ir = new_elements;

        match continue_running {
            ContinueRunning::Yes => {}
            ContinueRunning::No => break,
        }
    }

    // Map out paragraphs
    let ir = if opts.make_paragraphs {
        heirarchy::paragraphs(ir)
    } else {
        ir
    };

    // Map out headers
    let contents = heirarchy::headers(ir);

    if warnings.len() == 0 {
        Res::Ok(Item {
            item: ContentIr::Div { contents },
            location: Some(location),
        })
    } else if warnings.len() == 1 {
        Res::Warn {
            item: Item {
                item: ContentIr::Div { contents },
                location: Some(location),
            },
            msg: warnings[0].clone().0,
        }
    } else {
        Res::Warnings {
            item: Item {
                item: ContentIr::Div { contents },
                location: Some(location),
            },
            msgs: warnings,
        }
    }
}

pub(crate) fn parse(
    elements: &Vec<ContentIr>,
    location: &Location,
    opts: Options,
) -> Res<(Vec<ContentIr>, ContinueRunning)> {
    let mut new = vec![];
    let mut continue_running = ContinueRunning::No;

    let mut warnings = vec![];

    for element in elements {
        match element {
            ContentIr::Unparsed {
                contents,
                validations,
            } => {
                // Attempt to process something.
                // If something was found, add it to the end and keep going.
                let ir;
                match try_process(contents, &location, opts, validations) {
                    Res::Ok(item) => ir = item.item,
                    Res::Warn { item, msg } => {
                        warnings.push((msg, item.location.clone()));
                        ir = item.item;
                    }
                    Res::Error { location, msg } => {
                        return Res::Error {
                            location: location.clone(),
                            msg,
                        }
                    }
                    Res::Warnings { item, mut msgs } => {
                        warnings.append(&mut msgs);
                        ir = item.item;
                    }
                }

                if let Some(mut ir) = ir {
                    new.append(&mut ir);
                    continue_running = ContinueRunning::Yes;
                }
                // Nothing matched, so return it as text.
                else if contents.len() > 0 {
                    let text: Vec<String> = contents.split("\n").map(|s| s.to_string()).collect();

                    // Validate each is under 256 characters for SEO/engagement purposes
                    const MAX_TEXT_CHARS: usize = 256;
                    const DISPLAY_TEXT_LEN: usize = 20;

                    for text in text.iter() {
                        let char_count = text.chars().count();

                        if char_count > MAX_TEXT_CHARS {
                            let display_text =
                                text[0..char_count.min(DISPLAY_TEXT_LEN)].to_string();

                            let display_text = if DISPLAY_TEXT_LEN < display_text.chars().count() {
                                format!("{}...", display_text)
                            } else {
                                display_text
                            };

                            let suggested_nl = text
                                [MAX_TEXT_CHARS..char_count.min(MAX_TEXT_CHARS + DISPLAY_TEXT_LEN)]
                                .to_string();

                            warnings.push((
                                format!(
                                    "\n\tParagraph '{}' exceeded limit of {} by {} characters!\n\tSuggested fix is newline at: '{}'",
                                    display_text,
                                    MAX_TEXT_CHARS,
                                    char_count - MAX_TEXT_CHARS,
                                    suggested_nl
                                ),
                                Some(location.clone()),
                            ));
                        }
                    }

                    new.append(
                        &mut text
                            .iter()
                            .map(|t| ContentIr::Text { text: t.clone() })
                            .collect(),
                    );
                }
            }
            _ => {
                new.push(element.clone());
            }
        }
    }

    let item = Item {
        item: (new, continue_running),
        location: Some(location.clone()),
    };

    if warnings.is_empty() {
        Res::Ok(item)
    } else if warnings.len() == 1 {
        Res::Warn {
            item,
            msg: warnings[0].0.clone(),
        }
    } else {
        Res::Warnings {
            item,
            msgs: warnings,
        }
    }
}

...

```

And finally the `hierarchy` module is created to make headers and paragraphs.

```
// parser/md/parse_contents/heirarchy.rs

use super::ContentIr;

pub fn headers(mut ir: Vec<ContentIr>) -> Vec<ContentIr> {
    // Do any hierarchal mappings
    let mut contents = vec![];
    let mut processing_header = None;
    let mut header_collection = vec![];

    while ir.len() > 0 {
        let i = ir.remove(0);

        match &i {
            ContentIr::Header { .. } => {
                // Push the previous header on to the contents
                if let Some(header) = processing_header {
                    let header_children = ContentIr::Div {
                        contents: header_collection,
                    };

                    header_collection = vec![header, header_children];

                    contents.push(ContentIr::Card(header_collection));
                    header_collection = vec![];
                }

                processing_header = Some(i);
            }
            _ => {
                if processing_header.is_some() {
                    header_collection.push(i);
                } else {
                    contents.push(i);
                }
            }
        }
    }

    // If there's a working header, add it to the end
    if let Some(header) = processing_header {
        let header_children = ContentIr::Div {
            contents: header_collection,
        };

        header_collection = vec![header, header_children];

        contents.push(ContentIr::Card(header_collection));
    }

    contents
}

pub fn paragraphs(mut ir: Vec<ContentIr>) -> Vec<ContentIr> {
    let mut contents = vec![];

    let mut paragraph_collection = vec![];
    let mut prev_element_is_text = false;

    while ir.len() > 0 {
        let i = ir.remove(0);

        let paragraph_child;
        let mut is_text = false;

        match i {
            ContentIr::Card(_) => paragraph_child = false,
            ContentIr::Codeblock(_) => paragraph_child = false,
            ContentIr::Div { .. } => paragraph_child = false,
            ContentIr::Header { .. } => paragraph_child = false,
            ContentIr::InlineCode(_) => paragraph_child = true,
            ContentIr::Link { .. } => paragraph_child = true,
            ContentIr::Metadata(_) => paragraph_child = false,
            ContentIr::OrderedList { .. } => paragraph_child = false,
            ContentIr::Paragraph { .. } => paragraph_child = false,
            ContentIr::Text { text: _ } => {
                is_text = true;
                paragraph_child = true;
            }
            ContentIr::Unparsed { .. } => paragraph_child = false,
            ContentIr::UnorderedList { .. } => paragraph_child = false,
        }

        if !paragraph_child {
            if paragraph_collection.len() > 0 {
                contents.push(ContentIr::Paragraph {
                    children: paragraph_collection.clone(),
                });
            }

            paragraph_collection.clear();
            contents.push(i);
        } else {
            if prev_element_is_text && is_text {
                contents.push(ContentIr::Paragraph {
                    children: paragraph_collection.clone(),
                });
                paragraph_collection.clear();
            }

            paragraph_collection.push(i);
        }

        prev_element_is_text = is_text;
    }

    if paragraph_collection.len() > 0 {
        contents.push(ContentIr::Paragraph {
            children: paragraph_collection,
        });
    }

    contents
}

```

With that I can now go through and update all content to pass the warnings and errors.

I've tweaked the above numbers to make it more readable on iPads. That will be the target device.