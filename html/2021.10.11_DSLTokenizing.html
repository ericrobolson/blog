
<!DOCTYPE html>
<html>
    <head>
        <title>DSLs Part 3: Tokenizing</title>
        <!-- metadata -->
        <meta charset="UTF-8">
<meta name="description" content="Implementing a basic tokenizer.">
<meta name="keywords" content="rust, domain, specific, language, parsing, structure, generation, parsing">
<meta name="author" content="Eric Olson">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
        <!-- css -->
        <link rel="stylesheet" href="assets/styles.css">
    </head>
    <body>
        <!-- page class -->
        <div class=pageLight>
            <!-- content wrapper -->
            <div class=contentWrapperLight>
                <!-- content -->
                <div   ><div   ><div   class="navbottomLight"><a id="previous_page_link" href="2021.10.11_DSLContinued.html"  >ðŸ¡„ Previous</a>
Forward ðŸ¡†</div>
<div   class="navtopLight"><a id="homeNav" href="index.html"  >Home</a>
<a id="catalogNav" href="catalog.html"  >Catalog</a>
<a id="projectsNav" href="projects.html"  >Projects</a>
<a id="aboutMeNav" href="about_me.html"  >About Me</a></div></div>
<div   ><h2 id="title"  ><a  href="#title"  >#</a>
2021.10.11 - DSLs Part 3: Tokenizing</h2>
<div   >



<div   class="cardLight hoverShadowLight outlinedLight paddedbottomLight paddedtopLight shadowLight alignmentleftLight"><h3 id="0629"  ><a  href="#0629"  >#</a>
 0629</h3>
<div   ><p   >I'll be taking a different tack right now and switch over to tokenizing.</p>
<p   >One thing I want to try out is a entity driven approach, similar to an ECS in game development. There's a lot of metadata that is attributed to a token or piece of code, so I'll play around with slowly building that up over time.</p>
<p   >I'll start by adding a new macro to make types backed by usizes.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
// macro.rs
macro_rules! make_str_type {
    ($id:ident) => {
        #[derive(Copy, Clone, Debug, PartialEq)]
        pub struct $id&lt;'a>(&amp;'a str);

        impl&lt;'a> From&lt;&amp;'a str> for $id&lt;'a> {
            fn from(s: &amp;'a str) -> Self {
                Self(s)
            }
        }
    };
}

macro_rules! make_usize_type {
    ($id:ident) => {
        #[derive(Copy, Clone, Debug, PartialEq)]
        pub struct $id(usize);

        impl From&lt;usize> for $id {
            fn from(u: usize) -> Self {
                Self(u)
            }
        }
    };
}
</div>
<p   >I'll wire up the various types I'll utilize. These include lines, columns, entities and files.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
// types.rs
make_str_type!(File);
make_str_type!(Token);

make_usize_type!(Column);
make_usize_type!(Line);

#[derive(Copy, Clone, Debug, PartialEq)]
pub struct Entity&lt;'a> {
    pub file: Option&lt;File&lt;'a>>,
    pub location: Location,
    pub token: Token&lt;'a>,
}

#[derive(Copy, Clone, Debug, PartialEq)]
pub struct Location {
    pub column: Column,
    pub line: Line,
}
</div>
<p   >Finally I'll stub out the method that will parse the code. It's partly implemented with some tests so I can fill in the blanks as time goes on.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
// tokenizer.rs
pub use crate::prelude::*;

pub fn tokenize&lt;'a>(code: &amp;'a str, file: Option&lt;File&lt;'a>>) -> Vec&lt;Entity&lt;'a>> {
    let mut entities = vec![];

    let mut line = 0;
    let mut column = 0;

    let mut token_start_idx = 0;
    let mut token_end_idx = 0;

    let mut terminated = false;

    for c in code.chars() {
        // TODO: update token start and token end idx
        // TODO: handle comments?
        // TODO: handle brackets?
        // TODO: handle \r\n and \n cases

        if terminated {
            entities.push(make_token(
                &amp;code[token_start_idx..token_end_idx],
                file,
                line,
                column,
            ));

            terminated = false;
        }
    }

    entities
}

/// Helper func for making a token
fn make_token&lt;'a>(s: &amp;'a str, file: Option&lt;File&lt;'a>>, ln: usize, col: usize) -> Entity&lt;'a> {
    Entity {
        file,
        location: Location {
            column: col.into(),
            line: ln.into(),
        },
        token: s.into(),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn one_token() {
        let input = "wut";
        let expected: Vec&lt;Entity&lt;'_>> = vec![make_token("wut", None, 0, 0)];

        assert_eq!(expected, tokenize(input, None));
    }

    #[test]
    fn two_tokens() {
        let input = "wut up";
        let expected: Vec&lt;Entity&lt;'_>> =
            vec![make_token("wut", None, 0, 0), make_token("up", None, 0, 4)];

        assert_eq!(expected, tokenize(input, None));
    }

    #[test]
    fn two_tokens_with_nl() {
        let input = "wut \n up";
        let expected: Vec&lt;Entity&lt;'_>> =
            vec![make_token("wut", None, 0, 0), make_token("up", None, 1, 1)];

        assert_eq!(expected, tokenize(input, None));
    }
}
</div>
<p   >I don't really know what I'll end up using this for, but it will at least give me a launching point for anything I write that seems like it needs to parse code. </p>
<p   >There's two ways I can take this:</p>
<ol  type="1" class="listLight"><li><div   > An approach like Lisp with many parenthesis</div></li><li><div   > An approach like Haskell where things are split by whitespace</div></li></ol>
<p   >I'm leaning towards 2 as I generally prefer Haskell like syntax and I think it removes a lot of boilerplate (such as ';').</p></div></div>
<div   class="cardLight hoverShadowLight outlinedLight paddedbottomLight paddedtopLight shadowLight alignmentleftLight"><h3 id="1708"  ><a  href="#1708"  >#</a>
 1708</h3>
<div   ><p   >I've implemented the tokenizer function a bit more. I still need to figure out comments + parenthesis, but I'm not worried about that right now.</p>
<p   >While I suppose an optimal solution would be to tokenize everything and then calculate comments, lists, brackets, etc. separately, I don't want to deal with that in another level. It will be trivial to add in so I'll do that next session.</p>
<p   >Here's the updated code + tests:</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
pub use crate::prelude::*;

pub fn tokenize&lt;'a>(code: &amp;'a str, file: Option&lt;File&lt;'a>>) -> Vec&lt;Entity&lt;'a>> {
    let mut entities = vec![];

    let chars_len = code.chars().count();
    let end_idx = if chars_len == 0 { 0 } else { chars_len - 1 };

    let mut column = 0;
    let mut idx = 0;
    let mut line = 0;
    let mut start_column = 0;
    let mut terminated;
    let mut token_end_idx = 0;
    let mut token_start_idx = 0;

    for c in code.chars() {
        // TODO: handle comments?
        // TODO: handle brackets + parenthesis + curly brackets

        // Add a new line if necessary
        if c == '\n' {
            // If needing to handle \r\n specifically, modify code in here.
            // For now it treats \r as whitespace and will break on \n.
            line += 1;
            column = 0;
        } else {
            column += 1;
        }

        terminated = c.is_whitespace() || idx == end_idx;
        token_end_idx += 1;

        if terminated {
            // Only push non-whitespace chars
            if !code[token_start_idx..token_end_idx].trim().is_empty() {
                entities.push(make_token(
                    &amp;code[token_start_idx..token_end_idx].trim(),
                    file,
                    line,
                    start_column,
                ));
            }

            token_start_idx = token_end_idx;
            start_column = column;
        }

        idx += 1;
    }

    entities
}

/// Helper func for making a token
fn make_token&lt;'a>(s: &amp;'a str, file: Option&lt;File&lt;'a>>, ln: usize, col: usize) -> Entity&lt;'a> {
    Entity {
        file,
        location: Location {
            column: col.into(),
            line: ln.into(),
        },
        token: s.into(),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn one_token() {
        let input = "wut";
        let expected: Vec&lt;Entity&lt;'_>> = vec![make_token("wut", None, 0, 0)];

        assert_eq!(expected, tokenize(input, None));
    }

    #[test]
    fn one_token_with_starting_spaces() {
        let input = "    wut";
        let expected: Vec&lt;Entity&lt;'_>> = vec![make_token("wut", None, 0, 4)];

        assert_eq!(expected, tokenize(input, None));
    }

    #[test]
    fn one_token_with_ending_spaces() {
        let input = "wut    ";
        let expected: Vec&lt;Entity&lt;'_>> = vec![make_token("wut", None, 0, 0)];

        assert_eq!(expected, tokenize(input, None));
    }

    #[test]
    fn two_tokens() {
        let input = "wut up";
        let expected: Vec&lt;Entity&lt;'_>> =
            vec![make_token("wut", None, 0, 0), make_token("up", None, 0, 4)];

        assert_eq!(expected, tokenize(input, None));
    }

    #[test]
    fn two_tokens_with_spaces() {
        let input = "wut   up";
        let expected: Vec&lt;Entity&lt;'_>> =
            vec![make_token("wut", None, 0, 0), make_token("up", None, 0, 6)];

        assert_eq!(expected, tokenize(input, None));
    }

    #[test]
    fn two_tokens_with_new_line() {
        let input = "wut \n up";
        let expected: Vec&lt;Entity&lt;'_>> =
            vec![make_token("wut", None, 0, 0), make_token("up", None, 1, 1)];

        assert_eq!(expected, tokenize(input, None));
    }

    #[test]
    fn two_tokens_with_return_newline() {
        let input = "wut \r\n up";
        let expected: Vec&lt;Entity&lt;'_>> =
            vec![make_token("wut", None, 0, 0), make_token("up", None, 1, 1)];

        assert_eq!(expected, tokenize(input, None));
    }

    #[test]
    fn many_tokens_with_return_newline() {
        let input = "wut \r\n up    \n     my dawg";
        let expected: Vec&lt;Entity&lt;'_>> = vec![
            make_token("wut", None, 0, 0),
            make_token("up", None, 1, 1),
            make_token("my", None, 2, 5),
            make_token("dawg", None, 2, 8),
        ];

        assert_eq!(expected, tokenize(input, None));
    }
}
</div>
<p   >I've updated my roadmap to handle brackets + comments. From there I can look into analyzing the code and building a parse tree.</p></div></div></div></div></div>
            </div>
        </div>
    </body>
</html>
