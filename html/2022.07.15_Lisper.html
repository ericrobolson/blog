
<!DOCTYPE html>
<html>
    <head>
        <title>Lisper</title>
        <!-- metadata -->
        <meta charset="UTF-8">
<meta name="description" content="Separating the front end for the compiler">
<meta name="keywords" content="rust, json, parser, compiler, tokenizer">
<meta name="author" content="Eric Olson">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
        <!-- css -->
        <link rel="stylesheet" href="assets/styles.css">
    </head>
    <body>
        <!-- page class -->
        <div class=pageLight>
            <!-- content wrapper -->
            <div class=contentWrapperLight>
                <!-- content -->
                <div   ><div   ><div   class="navbottomLight"><a id="previous_page_link" href="2022.07.13_ClimbingAndEggLang.html"  >ðŸ¡„ Previous</a>
Forward ðŸ¡†</div>
<div   class="navtopLight"><a id="homeNav" href="index.html"  >Home</a>
<a id="catalogNav" href="catalog.html"  >Catalog</a>
<a id="projectsNav" href="projects.html"  >Projects</a>
<a id="aboutMeNav" href="about_me.html"  >About Me</a></div></div>
<div   ><h2 id="title"  ><a  href="#title"  >#</a>
2022.07.15 - Lisper</h2>
<div   >



<div   class="cardLight hoverShadowLight outlinedLight paddedbottomLight paddedtopLight shadowLight alignmentleftLight"><h3 id="0704"  ><a  href="#0704"  >#</a>
 0704</h3>
<div   ><p   >I've decided to split off the front end of my compiler into a separate repo. Why? I want to work on some other projects as I've hit a roadblock with EggLang. Functions are proving harder than I had anticipated and I want to work on other projects.</p>
<p   >I will certainly circle back to EggLang, but for now I will take what I have and get it into a useable state. <a  href="https://github.com/ericrobolson/Lisper"  >Lisper</a> is the result. I'll go into a brief overview, but as always analyzing the repo itself will provide the most information.</p>
<p   >The design was done in a bottom up fashion, iterating on one test at a time. I knew I was going to need locations of each individual token so I started with that.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
// location.rs

use std::path::PathBuf;

#[derive(Clone, Debug, PartialEq)]
pub struct Location {
    pub line: usize,
    pub column: usize,
    pub path: PathBuf,
}

impl Location {
    pub fn new(path: PathBuf) -> Self {
        Self {
            line: 0,
            column: 0,
            path,
        }
    }

    pub fn increment_line(mut self) -> Self {
        self.line += 1;
        self
    }
}
</div>
<p   >From there I can build out an <span   class="codeblockDark outlinedDark">Error</span> struct that returns the location as well as the type of error that occured.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
// error.rs

use std::path::PathBuf;

#[derive(Clone, Debug, PartialEq)]
pub struct Location {
    pub line: usize,
    pub column: usize,
    pub path: PathBuf,
}

impl Location {
    pub fn new(path: PathBuf) -> Self {
        Self {
            line: 0,
            column: 0,
            path,
        }
    }

    pub fn increment_line(mut self) -> Self {
        self.line += 1;
        self
    }
}
</div>
<p   >The next task was building out the tokenizer. This is the lowest level part as it will take in a source file and split it up into various tokens. There will be a lot I don't cover, but I'll hit the highlights.</p>
<p   >The guts of the tokenizer is a method called <span   class="codeblockDark outlinedDark">tokenize()</span>. This takes in some contents and iterates over all of them on a character by character basis, constructing various primitives as it goes along.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
    /// tokenize the given contents into a series of tokens.
    pub fn tokenize&lt;'a>(contents: &amp;'a str, path: PathBuf) -> Result&lt;Success, Err> {
        let mut tokenizer = Self::load(contents, path);

        let mut prev_char = None;
        while let Some(c) = tokenizer.next_character() {
</div>
<p   >From there I need to do some calculations to drive logic down the line. This involves looking at previous states as well as analyzing the character itself.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
            let is_comment = c == COMMENT;
            let is_quote = c == QUOTE;
            let is_whitespace = c.is_whitespace();
            let prev_char_is_escape = Some(ESCAPE_CHARACTER) == prev_char;
            let is_newline = c == NEW_LINE;
            let is_symbol = is_symbol(c);
            let is_making_comment = tokenizer.is_making_comment();
            let is_terminal_character = is_symbol | is_whitespace || is_comment || is_newline;
</div>
<p   >From there I will check if we're making a string. Strings are special as quoted quotation marks <span   class="codeblockDark outlinedDark">\"</span> signal that a string shouldn't be terminated.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
            // Handle making a string
            if tokenizer.is_making_string() {
                if is_quote &amp;&amp; !prev_char_is_escape {
                    tokenizer.make_string()?;
                } else {
                    let mut state = tokenizer.pop_string_state()?;
                    state.contents.push(c);
                    tokenizer.state_stack.push(State::String(state));
                }
            }
            // End the string
            else if is_quote &amp;&amp; !is_making_comment {
                if tokenizer.is_making_identifier() {
                    tokenizer.make_identifier()?;
                }

                tokenizer.state_stack.push(State::String(StringState {
                    start: tokenizer.location.clone(),
                    contents: String::new(),
                }));
</div>
<p   >The next part is checking for terminal characters, such as newlines, comments, symbols and whitespace. These are important as they split tokens.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
            } else if is_terminal_character {
                if is_whitespace &amp;&amp; tokenizer.state_stack.is_empty() {
                    // do nothing
                } else {
                    let mut skip_symbol = false;

                    if tokenizer.is_making_identifier() {
                        tokenizer.make_identifier()?;
                    }

                    if is_comment &amp;&amp; !is_making_comment {
                        tokenizer.state_stack.push(State::Comment(CommentState {
                            start: tokenizer.location.clone(),
                            contents: String::new(),
                        }));
                    } else if is_making_comment {
                        if !is_comment {
                            tokenizer.push_char_on_comment(c)?;
                            skip_symbol = true;
                        }
                    }

                    if is_newline &amp;&amp; tokenizer.is_making_comment() {
                        tokenizer.make_comment()?;
                    }

                    if is_symbol &amp;&amp; !skip_symbol {
                        tokenizer.tokens.push(Token {
                            kind: TokenKind::Symbol(c),
                            location: tokenizer.location.clone(),
                        });
                    }
                }
            } 
</div>
<p   >Finally we check to see if we need to handle comments or identifiers. These will simply start new states or add to existing ones.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
            else if tokenizer.is_making_identifier() {
                let mut state = tokenizer.pop_identifier_state()?;
                state.contents.push(c);
                tokenizer.state_stack.push(State::Identifier(state));
            } else if tokenizer.is_making_comment() {
                tokenizer.push_char_on_comment(c)?;
            } else {
                // Start identifier
                tokenizer
                    .state_stack
                    .push(State::Identifier(IdentifierState {
                        start: tokenizer.location.clone(),
                        contents: c.to_string(),
                    }));
            }
</div>
<p   >Finally we keep track of the previous character, increment the token location and finalize once done iterating through all characters.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
            prev_char = Some(c);
            tokenizer.increment_location(c);
        }

        tokenizer.finalize()
    }
</div>
<p   >While there is much more to dig in to, I feel that it is sufficient to get a grasp on how the tokenizer works.</p>
<p   >Once that is done the list of tokens is passed in to the parser. Like before, I will only tackle the main <span   class="codeblockDark outlinedDark">parse()</span> method. This is far simpler as we simply go through each token and construct a list. Everything in this parser can be represented as any of the following:</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
#[derive(Debug, Clone, PartialEq)]
pub enum Ast {
    List(Vec&lt;Node>),
    Comment(String),
    Identifier(String),
    Number(f64),
    String(String),
}
</div>
<p   >These get wrapped up in a <span   class="codeblockDark outlinedDark">Node</span>.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
#[derive(Debug, Clone, PartialEq)]
pub struct Node {
    pub ast: Ast,
    pub tokens: Vec&lt;Token>,
}
</div>
<p   >The main difference between the tokenizer is that the parser constructs lists and simplifies tokens. Like before, we iterate over all input (tokens in this case) and construct the nodes from that.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
// parser.rs

 /// Attempts to parse the given tokens into a vec of nodes.
    pub fn parse(tokens: Vec&lt;Token>) -> Result&lt;Vec&lt;Node>, Err> {
        let mut parser = Self::new(tokens);

        while let Some(token) = parser.next_token() {
            match &amp;token.kind {
                TokenKind::Comment(comment) => {
                    let node = Node {
                        ast: Ast::Comment(comment.clone()),
                        tokens: vec![token],
                    };
                    parser.add_node(node)?;
                }
                TokenKind::Number(n) => {
                    let node = Node {
                        ast: Ast::Number(*n),
                        tokens: vec![token],
                    };
                    parser.add_node(node)?;
                }
                TokenKind::Identifier(id) => {
                    let node = Node {
                        ast: Ast::Identifier(id.clone()),
                        tokens: vec![token],
                    };
                    parser.add_node(node)?;
                }
                TokenKind::String(string) => {
                    let node = Node {
                        ast: Ast::String(string.clone()),
                        tokens: vec![token],
                    };
                    parser.add_node(node)?;
                }
                TokenKind::Symbol('(') => {
                    parser.start_list(token);
                }
                TokenKind::Symbol(')') => {
                    parser.end_list(token)?;
                }
                t => todo!("Parse token: {:#?}", t),
            }
        }

        parser.finalize()
    }

</div>
<p   >These are exposed as a <span   class="codeblockDark outlinedDark">parse()</span> method in the <span   class="codeblockDark outlinedDark">lib.rs</span> file so that users don't have to worry about the internals of this crate.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
// lib.rs

/// Parse the given contents into a vec of nodes.
pub fn parse&lt;'a>(contents: &amp;'a str, path: std::path::PathBuf) -> Result&lt;Vec&lt;Node>, Error> {
    let tokens = tokenizer::Tokenizer::tokenize(contents, path)?;
    let nodes = parser::Parser::parse(tokens)?;

    Ok(nodes)
}

/// Errors that may occur during parsing.
#[derive(Debug, Clone, PartialEq)]
pub enum Error {
    Tokenizer(tokenizer::Err),
    Parser(parser::Err),
}

impl From&lt;parser::Err> for Error {
    fn from(err: parser::Err) -> Self {
        Self::Parser(err)
    }
}

impl From&lt;tokenizer::Err> for Error {
    fn from(err: tokenizer::Err) -> Self {
        Self::Tokenizer(err)
    }
}
</div>
<p   >While I will be pausing EggLang, the compiler that this code is based off of, I would like to go back in the future and extend it. For now though I have a few app ideas I want to try out and will be iterating on those.</p></div></div></div></div></div>
            </div>
        </div>
    </body>
</html>
