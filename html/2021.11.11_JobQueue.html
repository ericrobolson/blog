
<!DOCTYPE html>
<html>
    <head>
        <title>Creating a Job Queue</title>
        <!-- metadata -->
        <meta charset="UTF-8">
<meta name="description" content="Creating a Job Queue and other threading primitives in Rust.">
<meta name="keywords" content="rust, open, source, mit, timer, timing, crate, library, gamedev, ggez, job, queue, multithreading">
<meta name="author" content="Eric Olson">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
        <!-- css -->
        <link rel="stylesheet" href="assets/styles.css">
    </head>
    <body>
        <!-- page class -->
        <div class=pageLight>
            <!-- content wrapper -->
            <div class=contentWrapperLight>
                <!-- content -->
                <div   ><div   ><div   class="navbottomLight"><a id="previous_page_link" href="2021.11.10_Drawing.html"  >ðŸ¡„ Previous</a>
<a id="next_page_link" href="2021.11.12_Scripting.html"  >Forward ðŸ¡†</a></div>
<div   class="navtopLight"><a id="homeNav" href="index.html"  >Home</a>
<a id="catalogNav" href="catalog.html"  >Catalog</a>
<a id="projectsNav" href="projects.html"  >Projects</a>
<a id="aboutMeNav" href="about_me.html"  >About Me</a></div></div>
<div   ><h2 id="title"  ><a  href="#title"  >#</a>
2021.11.11 - Creating a Job Queue</h2>
<div   >



<div   class="cardLight hoverShadowLight outlinedLight paddedbottomLight paddedtopLight shadowLight alignmentleftLight"><h3 id="0742"  ><a  href="#0742"  >#</a>
 0742</h3>
<div   ><p   >I'll go over a job queue I wrote recently. </p>
<p   >This can be found on my <a  href="https://github.com/ericrobolson/g_threading"  >g_threading repo</a>.</p>
<p   >A job queue is a queue that runs on multiple threads, handing out work as needed. There are a ton of optimizations that can be made for this, such as using read-write locks or making it lockless, but I'll keep it simple for now.</p>
<p   >Like other projects, I'll wrap the core bits in a feature that can be turned on or off.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
// job_queue/mod.rs
#[cfg(feature = "threaded")]
mod thread_handler;

/// Structure containing job queue related functionality.
pub struct JobQueue {}
pub type Job = alloc::boxed::Box&lt;dyn FnOnce() + Send + 'static>;

impl JobQueue {
    /// The number of jobs currently processing
    #[allow(unreachable_code)]
    pub fn num_jobs() -> usize {
        // Queue up job if threading is enabled
        #[cfg(feature = "threaded")]
        {
            return thread_handler::THREAD_HANDLER.lock().unwrap().num_jobs();
        }

        0
    }

    /// Queues up the given job for execution.
    #[allow(unreachable_code)]
    pub fn queue(f: Job) {
        // Queue up job if threading is enabled
        #[cfg(feature = "threaded")]
        {
            thread_handler::THREAD_HANDLER.lock().unwrap().queue(f);
            return;
        }

        // Otherwise execute the function since it's a single threaded environment.
        f();
    }
}
</div>
<p   >This calls out to a <span   class="codeblockDark outlinedDark">lazy_static</span> object like I've used in the past. The top level interface is simple, providing only two methods.</p>
<p   >Within is a <span   class="codeblockDark outlinedDark">thread_handler</span> module, which contains the actual implementation. When initialized it will spawn N-1 threads where N is the number of CPUs. Each thread will then attempt to take a task off the top of the queue if it exists.</p>
<div   class="codeblockDark contentWrapperLight hoverShadowLight outlinedDark paddedbottomLight paddedtopLight shadowLight">
// thread_handler.rs
use super::Job;
use std::{
    sync::{
        mpsc::{channel, Sender},
        Mutex,
    },
    thread::{self, JoinHandle},
    time::Duration,
};

const DEFAULT_JOB_CAPACITY: usize = 256;

lazy_static! {
    pub(crate) static ref THREAD_HANDLER: Mutex&lt;ThreadHandler> = Mutex::new(ThreadHandler::new());
}

struct Thread {
    handle: Option&lt;JoinHandle&lt;()>>,
    sender: Sender&lt;ThreadMessage>,
}

enum ThreadMessage {
    Shutdown,
}

pub struct ThreadHandler {
    active_jobs: usize,
    jobs: Vec&lt;Job>,
    threads: Vec&lt;Thread>,
}

impl ThreadHandler {
    pub fn new() -> Self {
        // Cap the CPUs to 1 less than the max
        let num_cpus = if let Some(num) = num_cpus::get().checked_sub(1) {
            num
        } else {
            0
        };

        let mut threads = vec![];

        // Spawn threads
        for _ in 0..num_cpus {
            let (sender, receiver) = channel();

            // Spawn the actual thread
            let handle = thread::spawn(move || {
                let original_backoff = Duration::from_micros(10);
                let max_backoff = Duration::from_millis(1);
                let mut backoff = Duration::from_micros(10);

                // Endlessly loop the thread
                loop {
                    // Check parent messages.
                    for msg in receiver.try_iter() {
                        match msg {
                            // Exit if it should shutdown
                            ThreadMessage::Shutdown => return,
                        }
                    }

                    // Attempt to get a job from the queue
                    let job = {
                        let mut handler = THREAD_HANDLER.lock().unwrap();
                        if handler.jobs.is_empty() == false {
                            THREAD_HANDLER.lock().unwrap().decrement_jobs();

                            Some(handler.jobs.remove(0))
                        } else {
                            None
                        }
                    };

                    // Reset backoff + execute job if it exists
                    if let Some(job) = job {
                        backoff = original_backoff;
                        job();
                    } else {
                        // Otherwise exponential backoff to prevent it from going bonkers
                        backoff *= 2;
                        if backoff > max_backoff {
                            backoff = max_backoff;
                        }
                    }
                }
            });

            // Save handle
            threads.push(Thread {
                sender,
                handle: Some(handle),
            });
        }

        Self {
            active_jobs: 0,
            jobs: Vec::with_capacity(DEFAULT_JOB_CAPACITY), // arbitrary
            threads,
        }
    }

    /// Decrements all active jobs
    fn decrement_jobs(&amp;mut self) {
        if self.active_jobs > 0 {
            self.active_jobs -= 1;
        }
    }

    /// The number of jobs currently processing
    pub fn num_jobs(&amp;self) -> usize {
        self.active_jobs
    }

    /// Queues the given method.
    #[allow(unreachable_code)]
    pub fn queue(&amp;mut self, f: Job) {
        // If no threads, simply execute the function.
        if self.threads.is_empty() {
            f();
        } else {
            // Push thread onto queue
            self.jobs.push(f);
            self.active_jobs += 1;
        }
    }
}

impl Drop for ThreadHandler {
    fn drop(&amp;mut self) {
        // Clean up by joining all threads.
        for thread in self.threads.iter_mut() {
            // SHut it down
            match thread.sender.send(ThreadMessage::Shutdown) {
                Ok(_) => {}
                Err(_) => {}
            }

            // Join the thread
            if let Some(handle) = thread.handle.take() {
                match handle.join() {
                    Ok(_) => {}
                    Err(_) => {}
                }
            }
        }
    }
}
</div>
<p   >With that I'll go through and add in some simple multithreading to my app.</p></div></div></div></div></div>
            </div>
        </div>
    </body>
</html>
